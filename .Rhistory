y_train_logit_centered <- y_train_logit - y_train_logit_mean
# test data set
W_test_centered <- kidney_obj$W_test
y_test <- kidney_obj$y_test
#MSE trend
L_trend_0_logit <- rep(NA, L_max)
for(L in 1:L_max){
#learn the model
pls_model_transform <- nipals_pen_hybrid(
W_train_centered, y_train_logit_centered, L, lambda, 0)
# predict
y_pred_pls <- predict_test(pls_model_transform, W_test_centered)
#inverse transform
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
# calculate the mse and save
L_trend_0_logit[L] <- mse(y_pred_pls, y_test)
}
plot(L_trend_0_logit[1:L_max], main ="hybridPLS", ylab = "MSE", xlab = "number of iteration", pch=".", ylim=y_limit)
lines(L_trend_0_logit)
mse[1] <- min(L_trend_0_logit, omit.NA = TRUE)
mse[1]
#1. curve normalization 구현
#2
y_limit = c(0.04, 0.15)
mse <- rep(NA, 5)
names(mse) <- c("hybridPLS", "sofreg", "FPCA+PCAreg", "PLS", "PCA+PLS")
# 1. HybridPLS
seed = 1
set.seed(seed) # for training/test split
n_basis = 20
#set the number of max iterations
L_max = 100
lambda = c(1e-6,5*1e-6)
kidney_obj <- read_fd_kidney(
test_ratio = 0.3,
n_basis = n_basis,
normalize = list("curve" = TRUE, "scalar"= TRUE, "between" = TRUE)
)
# W is already centered
W_train_centered <- kidney_obj$W_train
y_train <- kidney_obj$y_train
# minmax scale and logit transform and centering
y_train_min <- min(y_train)
y_train_max <- max(y_train)
y_train_logit <- response_transform_min_max_logit(y_train,
y_train_min,
y_train_max)
y_train_logit_mean <- mean(y_train_logit) #centering again, for PLS algorithm
y_train_logit_centered <- y_train_logit - y_train_logit_mean
# test data set
W_test_centered <- kidney_obj$W_test
y_test <- kidney_obj$y_test
#MSE trend
L_trend_0_logit <- rep(NA, L_max)
for(L in 1:L_max){
#learn the model
pls_model_transform <- nipals_pen_hybrid(
W_train_centered, y_train_logit_centered, L, lambda, 0)
# predict
y_pred_pls <- predict_test(pls_model_transform, W_test_centered)
#inverse transform
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
# calculate the mse and save
L_trend_0_logit[L] <- mse(y_pred_pls, y_test)
}
plot(L_trend_0_logit[1:L_max], main ="hybridPLS", ylab = "MSE", xlab = "number of iteration", pch=".", ylim=y_limit)
lines(L_trend_0_logit)
mse[1] <- min(L_trend_0_logit, omit.NA = TRUE)
mse[1]
#1. curve normalization 구현
#2
y_limit = c(0.04, 0.15)
mse <- rep(NA, 5)
names(mse) <- c("hybridPLS", "sofreg", "FPCA+PCAreg", "PLS", "PCA+PLS")
# 1. HybridPLS
seed = 1
set.seed(seed) # for training/test split
n_basis = 20
#set the number of max iterations
L_max = 10
lambda = c(1e-6,5*1e-6)
kidney_obj <- read_fd_kidney(
test_ratio = 0.3,
n_basis = n_basis,
normalize = list("curve" = TRUE, "scalar"= TRUE, "between" = TRUE)
)
# W is already centered
W_train_centered <- kidney_obj$W_train
y_train <- kidney_obj$y_train
# minmax scale and logit transform and centering
y_train_min <- min(y_train)
y_train_max <- max(y_train)
y_train_logit <- response_transform_min_max_logit(y_train,
y_train_min,
y_train_max)
y_train_logit_mean <- mean(y_train_logit) #centering again, for PLS algorithm
y_train_logit_centered <- y_train_logit - y_train_logit_mean
# test data set
W_test_centered <- kidney_obj$W_test
y_test <- kidney_obj$y_test
#MSE trend
L_trend_0_logit <- rep(NA, L_max)
for(L in 1:L_max){
#learn the model
pls_model_transform <- nipals_pen_hybrid(
W_train_centered, y_train_logit_centered, L, lambda, 0)
# predict
y_pred_pls <- predict_test(pls_model_transform, W_test_centered)
#inverse transform
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
# calculate the mse and save
L_trend_0_logit[L] <- mse(y_pred_pls, y_test)
}
plot(L_trend_0_logit[1:L_max], main ="hybridPLS", ylab = "MSE", xlab = "number of iteration", pch=".", ylim=y_limit)
lines(L_trend_0_logit)
mse[1] <- min(L_trend_0_logit, omit.NA = TRUE)
mse[1]
W_train_fd <- extract_fd(W_train_centered)
W_test_fd <- extract_fd(W_test_centered)
xfdlist <- betalist <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist[[1]] <- W_train_fd[[1]]
xfdlist[[2]] <- W_train_fd[[2]]
conbasis <- create.constant.basis(c(0, 1))
betabasis <- create.bspline.basis(c(0, 1),n_basis)
#betalist[[1]] <- conbasis
betalist[[1]] <- betabasis
betalist[[2]]<- betabasis
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
xfdlist_test  <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist_test[[1]] <- W_test_fd[[1]]
xfdlist_test[[2]] <- W_test_fd[[2]]
#inverse transform
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
mse[2] <- mse(y_pred_pls, y_test)
mse[2]
summary(sof_reg)
plot(sof_reg$betaestlist[[2]])
plot(sof_reg$betaestlist[[1]])
#inverse transform
y_pred_pls <- predict.fRegress(sof_reg, xfdlist_test)
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
mse[2] <- mse(y_pred_pls, y_test)
mse[2]
sqrt(0.11)
plot(sof_reg$betaestlist[[1]])
plot(sof_reg$betaestlist[[2]])
par(mfrow=c(2,1))
plot(sof_reg$betaestlist[[1]])
plot(sof_reg$betaestlist[[2]])
par(mfrow=c(1,1))
par(mfrow=c(2,1))
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
W_train_fd
plot(W_train_fd[1])
plot(W_train_fd[[1])
plot(W_train_fd[[1]])
plot(W_train_fd[[1]])
par(mfrow=c(2,1))
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
par(mfrow=c(1,1))
plot(W_train_fd[[1]])
plot(W_train_fd[[2]])
plot(W_train_fd[[1]])
plot(W_train_fd[[2]])
plot(mean(W_train_fd[[2]])
plot(mean(W_train_fd[[2]]))
plot(W_train_fd[[2]])
plot(W_train_fd[[2]][1])
plot(W_train_fd[[2]][2])
plot(W_train_fd[[2]][10])
plot(W_train_fd[[2]][20])
plot(W_train_fd[[2]][40])
plot(W_train_fd[[2]][90])
plot(W_train_fd[[2]][100])
plot(W_train_fd[[2]][40])
plot(W_train_fd[[2]][20])
par(mfrow=c(2,1))
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
par(mfrow=c(1,1))
W_train_centered
str(W_train_centered)
W_train_centered$Z
W_train_centered@Z
xfdlist[[3]] <- W_train_centered@Z[,1]
xfdlist[[3]]
betalist[[3]]<- conbasis
#betalist[[1]] <- conbasis
betalist[[1]] <- betabasis
betalist[[2]]<- betabasis
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
#  data are in Canadian Weather object
#  print the names of the data
print(names(CanadianWeather))
#  set up log10 of annual precipitation for 35 weather stations
annualprec <-
log10(apply(CanadianWeather$dailyAv[,,"Precipitation.mm"], 2,sum))
annualprec
# The simplest 'fRegress' call is singular with more bases
# than observations, so we use only 25 basis functions, for this example
smallbasis  <- create.fourier.basis(c(0, 365), 25)
# The covariate is the temperature curve for each station.
tempfd <- smooth.basis(day.5,
CanadianWeather$dailyAv[,,"Temperature.C"], smallbasis)$fd
precip.Temp1 <- fRegress(annualprec ~ tempfd)
#  the output is a list with class name fRegress, display names
names(precip.Temp1)
#  the vector of fits to the data is object  precip.Temp1$yfdPar,
#  but since the dependent variable is a vector, so is the fit
annualprec.fit1 <- precip.Temp1$yhatfdobj
#  plot the data and the fit
plot(annualprec.fit1, annualprec, type="p", pch="o")
lines(annualprec.fit1, annualprec.fit1, lty=2)
#  print root mean squared error
RMSE <- sqrt(mean((annualprec-annualprec.fit1)^2))
print(paste("RMSE =",RMSE))
#  plot the estimated regression function
plot(precip.Temp1$betaestlist[[2]])
#  This isn't helpful either, the coefficient function is too
#  complicated to interpret.
#  display the number of basis functions used:
print(precip.Temp1$betaestlist[[2]]$fd$basis$nbasis)
#  25 basis functions to fit 35 values, no wonder we over-fit the data
#  25 basis functions to fit 35 values, no wonder we over-fit the data
#  This isn't helpful either, the coefficient function is too
#  complicated to interpret.
#  display the number of basis functions used:
print(precip.Temp1$betaestlist[[2]]$fd$basis$nbasis)
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
n_basis = 10
xfdlist <- betalist <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist[[1]] <- W_train_fd[[1]]
xfdlist[[2]] <- W_train_fd[[2]]
#betalist[[1]] <- conbasis
betalist[[1]] <- betabasis
betalist[[2]]<- betabasis
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
xfdlist <- betalist <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist[[1]] <- W_train_fd[[1]]
xfdlist[[2]] <- W_train_fd[[2]]
kidney_obj <- read_fd_kidney(
test_ratio = 0.3,
n_basis = n_basis,
normalize = list("curve" = TRUE, "scalar"= TRUE, "between" = TRUE)
)
W_train_fd <- extract_fd(W_train_centered)
W_test_fd <- extract_fd(W_test_centered)
xfdlist <- betalist <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist[[1]] <- W_train_fd[[1]]
xfdlist[[2]] <- W_train_fd[[2]]
conbasis <- create.constant.basis(c(0, 1))
betabasis <- create.bspline.basis(c(0, 1),n_basis)
#betalist[[1]] <- conbasis
betalist[[1]] <- betabasis
betalist[[2]]<- betabasis
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
plot(sof_reg$betaestlist[[1]], main = "first coef function")
plot(sof_reg$betaestlist[[2]], main = "second coef funciton")
xfdlist_test  <- vector("list",2)
#xfdlist[[1]] <- rep(1, length(y_train_logit_centered))
xfdlist_test[[1]] <- W_test_fd[[1]]
xfdlist_test[[2]] <- W_test_fd[[2]]
#inverse transform
y_pred_pls <- predict.fRegress(sof_reg, xfdlist_test)
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
mse[2] <- mse(y_pred_pls, y_test)
mse[2]
seed = 1
set.seed(seed) # for training/test split
n_basis = 10
#set the number of max iterations
L_max = 10
lambda = c(1e-6,5*1e-6)
kidney_obj <- read_fd_kidney(
test_ratio = 0.3,
n_basis = n_basis,
normalize = list("curve" = TRUE, "scalar"= TRUE, "between" = TRUE)
)
# W is already centered
W_train_centered <- kidney_obj$W_train
y_train <- kidney_obj$y_train
# minmax scale and logit transform and centering
y_train_min <- min(y_train)
y_train_max <- max(y_train)
y_train_logit <- response_transform_min_max_logit(y_train,
y_train_min,
y_train_max)
y_train_logit_mean <- mean(y_train_logit) #centering again, for PLS algorithm
y_train_logit_centered <- y_train_logit - y_train_logit_mean
# test data set
W_test_centered <- kidney_obj$W_test
y_test <- kidney_obj$y_test
L_trend_0_logit <- rep(NA, L_max)
for(L in 1:L_max){
#learn the model
pls_model_transform <- nipals_pen_hybrid(
W_train_centered, y_train_logit_centered, L, lambda, 0)
# predict
y_pred_pls <- predict_test(pls_model_transform, W_test_centered)
#inverse transform
y_pred_pls <- reponse_inverse_transform_min_max_logit(
y_pred_pls, y_train_logit_mean, y_train_max, y_train_min)
# calculate the mse and save
L_trend_0_logit[L] <- mse(y_pred_pls, y_test)
}
plot(L_trend_0_logit[1:L_max], main ="hybridPLS", ylab = "MSE", xlab = "number of iteration", pch=".", ylim=y_limit)
lines(L_trend_0_logit)
mse[1] <- min(L_trend_0_logit, omit.NA = TRUE)
mse[1]
##
precip.Temp1 <- fRegress(annualprec ~ tempfd)
#  the output is a list with class name fRegress, display names
names(precip.Temp1)
#  the vector of fits to the data is object  precip.Temp1$yfdPar,
#  but since the dependent variable is a vector, so is the fit
annualprec.fit1 <- precip.Temp1$yhatfdobj
#  plot the data and the fit
plot(annualprec.fit1, annualprec, type="p", pch="o")
lines(annualprec.fit1, annualprec.fit1, lty=2)
#  print root mean squared error
RMSE <- sqrt(mean((annualprec-annualprec.fit1)^2))
print(paste("RMSE =",RMSE))
#  plot the estimated regression function
plot(precip.Temp1$betaestlist[[2]])
#  This isn't helpful either, the coefficient function is too
#  complicated to interpret.
#  display the number of basis functions used:
print(precip.Temp1$betaestlist[[2]]$fd$basis$nbasis)
#  25 basis functions to fit 35 values, no wonder we over-fit the data
##
## formula interface:  specify the model by a formula, the method
## fRegress.formula automatically sets up the regression coefficient functions,
## a constant function for the intercept,
## and a higher dimensional function
## for the inner product with temperature
##
xfdlist <- list(const=rep(1, 35), tempfd=tempfd)
# The intercept must be constant for a scalar response
betabasis1 <- create.constant.basis(c(0, 365))
betafd1    <- fd(0, betabasis1)
betafdPar1 <- fdPar(betafd1)
betafd2     <- create.bspline.basis(c(0, 365),7)
# convert to an fdPar object
betafdPar2  <- fdPar(betafd2)
betalist <- list(const=betafdPar1, tempfd=betafdPar2)
precip.Temp3   <- fRegress(annualprec, xfdlist, betalist)
annualprec.fit3 <- precip.Temp3$yhatfdobj
#  plot the data and the fit
plot(annualprec.fit3, annualprec, type="p", pch="o")
lines(annualprec.fit3, annualprec.fit3)
plot(precip.Temp3$betaestlist[[2]])
#try intercept
xfdlist <- list(const=rep(1, length(y_train_logit_centered)), tempfd=W_train_fd[[1]])
# The intercept must be constant for a scalar response
betabasis1 <- create.constant.basis(c(0, 1))
betafd1    <- fd(0, betabasis1)
betafdPar1 <- fdPar(betafd1)
betafd2     <- create.bspline.basis(c(0, 1),n_basis)
# convert to an fdPar object
betafdPar2  <- fdPar(betafd2)
betalist <- list(const=betafdPar1, tempfd=betafdPar2)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
betafd2     <- create.bspline.basis(c(0, 1),n_basis)
# convert to an fdPar object
betafdPar2  <- fdPar(betafd2)
betalist <- list(const=betafdPar1, tempfd=betafdPar2)
# The intercept must be constant for a scalar response
betabasis1 <- create.constant.basis(c(0, 1))
betafd1    <- fd(0, betabasis1) # this was important!
betafdPar1 <- fdPar(betafd1) # this was important!
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2,
"postcurve" = betafdPar2
)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
# The intercept must be constant for a scalar response
betabasis1 <- create.constant.basis(c(0, 1))
betafd1    <- fd(0, betabasis1) # this was important!
betafdPar1 <- fdPar(betafd1) # this was important!
betafd2     <- create.bspline.basis(c(0, 1),n_basis)
# convert to an fdPar object
betafdPar2  <- fdPar(betafd2)
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2,
"postcurve" = betafdPar2
)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
betafd3  <- create.bspline.basis(c(0, 1),n_basis)
betafdPar3  <- fdPar(betafd3) # convert to an fdPar object
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2,
"postcurve" = betafdPar2
)
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2,
"postcurve" = betafdPar3
)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
xfdlist
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
rep(1, length(y_train_logit_centered))
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]],
)
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]],
"postcurve" = W_train_fd[[2]]
)
# The intercept must be constant for a scalar response
betabasis1 <- create.constant.basis(c(0, 1))
betafd1    <- fd(0, betabasis1) # this was important!
betafdPar1 <- fdPar(betafd1) # this was important!
betafd2  <- create.bspline.basis(c(0, 1),n_basis)
betafdPar2  <- fdPar(betafd2) # convert to an fdPar object
betafd3  <- create.bspline.basis(c(0, 1),n_basis)
betafdPar3  <- fdPar(betafd3) # convert to an fdPar object
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2,
"postcurve" = betafdPar3
)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
betalist <- list(
"const" = betafdPar1,
"precurve" = betafdPar2
#, "postcurve" = betafdPar3
)
#try intercept
xfdlist <- list(
"const" = rep(1, length(y_train_logit_centered)),
"precurve" = W_train_fd[[1]]
#,"postcurve" = W_train_fd[[2]]
)
sof_reg <- fRegress(y_train_logit_centered, xfdlist, betalist)
sof_reg
library(refund)
install.packegs("refund")
install.packages("refund")
library(refund)
data(DTI)
FA.cca <- DTI[complete.cases(DTI$cca)]
FA.cca <- DTI[complete.cases(DTI$cca),]
FA.cca
FA.cca$ID <- factor(FA.cca$ID)
FA.cca$ID
fa.cca$cca
FA.cca$cca
re(ID)
re(FA.cca$ID)
soft.fit <- pfr(pasat ~ lf(cca, k=30, argvals = 1:93) + re(ID))
soft.fit <- pfr(pasat ~ lf(cca, k=30, argvals = 1:93) + re(ID))
soft.fit <- pfr(pasat ~ lf(cca, k=30, argvals = 1:93) + re(ID), data = FA.cca)
plot(soft.fit, select = 1)
plot(soft.fit, select = 2)
plot(soft.fit, select = 1)
head(FA.cca)
str(FA.cca)
FA.cca$pasat
kidney_table <- extract_value_kidney()
head(kidney_table)
