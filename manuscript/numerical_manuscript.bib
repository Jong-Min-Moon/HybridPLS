
@article{kramer_degrees_2011,
	title = {The {Degrees} of {Freedom} of {Partial} {Least} {Squares} {Regression}},
	volume = {106},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/jasa.2011.tm10107},
	doi = {10.1198/jasa.2011.tm10107},
	abstract = {The derivation of statistical properties for partial least squares regression can be a challenging task. The reason is that the construction of latent components from the predictor variables also depends on the response variable. While this typically leads to good performance and interpretable models in practice, it makes the statistical analysis more involved. In this work, we study the intrinsic complexity of partial least squares regression. Our contribution is an unbiased estimate of its degrees of freedom. It is defined as the trace of the first derivative of the fitted values, seen as a function of the response. We establish two equivalent representations that rely on the close connection of partial least squares to matrix decompositions and Krylov subspace techniques. We show that the degrees of freedom depend on the collinearity of the predictor variables: The lower the collinearity, the higher the complexity. In particular, they are typically higher than the naive approach that defines the degrees of freedom as the number of components. Further, we illustrate how our degrees of freedom estimate can be used for the comparison of different regression methods. In the experimental section, we show that our degrees of freedom estimate in combination with information criteria is useful for model selection.},
	number = {494},
	urldate = {2023-09-04},
	journal = {Journal of the American Statistical Association},
	author = {Krämer, Nicole and Sugiyama, Masashi},
	month = jun,
	year = {2011},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/jasa.2011.tm10107},
	keywords = {Dimensionality reduction, Information criteria, Krylov subspaces, Model selection},
	pages = {697--705},
	file = {Krämer and Sugiyama - 2011 - The Degrees of Freedom of Partial Least Squares Re.pdf:C\:\\Users\\Jongmin\\Zotero\\storage\\FFA77YVG\\Krämer and Sugiyama - 2011 - The Degrees of Freedom of Partial Least Squares Re.pdf:application/pdf},
}

@article{delaigle_methodology_2012,
	title = {Methodology and theory for partial least squares applied to functional data},
	volume = {40},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-40/issue-1/Methodology-and-theory-for-partial-least-squares-applied-to-functional/10.1214/11-AOS958.full},
	doi = {10.1214/11-AOS958},
	abstract = {The partial least squares procedure was originally developed to estimate the slope parameter in multivariate parametric models. More recently it has gained popularity in the functional data literature. There, the partial least squares estimator of slope is either used to construct linear predictive models, or as a tool to project the data onto a one-dimensional quantity that is employed for further statistical analysis. Although the partial least squares approach is often viewed as an attractive alternative to projections onto the principal component basis, its properties are less well known than those of the latter, mainly because of its iterative nature. We develop an explicit formulation of partial least squares for functional data, which leads to insightful results and motivates new theory, demonstrating consistency and establishing convergence rates.},
	number = {1},
	urldate = {2023-09-04},
	journal = {The Annals of Statistics},
	author = {Delaigle, Aurore and Hall, Peter},
	month = feb,
	year = {2012},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G08, central limit theorem, computational algorithm, consistency, Convergence rates, functional linear models, generalized Fourier basis, principal components, projection, stochastic expansion},
	pages = {322--352},
	file = {Full Text PDF:C\:\\Users\\Jongmin\\Zotero\\storage\\BLRGSBQW\\Delaigle and Hall - 2012 - Methodology and theory for partial least squares a.pdf:application/pdf},
}

@article{chiou_functional_2003,
	title = {Functional {Quasi}-{Likelihood} {Regression} {Models} with {Smooth} {Random} {Effects}},
	volume = {65},
	issn = {1369-7412},
	url = {https://www.jstor.org/stable/3647512},
	abstract = {We propose a class of semiparametric functional regression models to describe the influence of vector-valued covariates on a sample of response curves. Each observed curve is viewed as the realization of a random process, composed of an overall mean function and random components. The finite dimensional covariates influence the random components of the eigenfunction expansion through single-index models that include unknown smooth link and variance functions. The parametric components of the single-index models are estimated via quasi-score estimating equations with link and variance functions being estimated nonparametrically. We obtain several basic asymptotic results. The functional regression models proposed are illustrated with the analysis of a data set consisting of egg laying curves for 1000 female Mediterranean fruit-flies (medflies).},
	number = {2},
	urldate = {2023-09-30},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Chiou, Jeng-Min and Müller, Hans-Georg and Wang, Jane-Ling},
	year = {2003},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {405--423},
	file = {jrsssb_65_2_405.pdf:C\:\\Users\\Jongmin\\Zotero\\storage\\SF75CYGN\\jrsssb_65_2_405.pdf:application/pdf},
}

@article{jiang_covariate_2010,
	title = {Covariate adjusted functional principal components analysis for longitudinal data},
	volume = {38},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-38/issue-2/Covariate-adjusted-functional-principal-components-analysis-for-longitudinal-data/10.1214/09-AOS742.full},
	doi = {10.1214/09-AOS742},
	abstract = {Classical multivariate principal component analysis has been extended to functional data and termed functional principal component analysis (FPCA). Most existing FPCA approaches do not accommodate covariate information, and it is the goal of this paper to develop two methods that do. In the first approach, both the mean and covariance functions depend on the covariate Z and time scale t while in the second approach only the mean function depends on the covariate Z. Both new approaches accommodate additional measurement errors and functional data sampled at regular time grids as well as sparse longitudinal data sampled at irregular time grids. The first approach to fully adjust both the mean and covariance functions adapts more to the data but is computationally more intensive than the approach to adjust the covariate effects on the mean function only. We develop general asymptotic theory for both approaches and compare their performance numerically through simulation studies and a data set.},
	number = {2},
	urldate = {2023-09-30},
	journal = {The Annals of Statistics},
	author = {Jiang, Ci-Ren and Wang, Jane-Ling},
	month = apr,
	year = {2010},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G20, 62H25, 62M15, Functional data analysis, functional principal components analysis, local linear regression, longitudinal data analysis, smoothing, sparse data},
	pages = {1194--1226},
	file = {Jiang_Wang_2010_Covariate adjusted functional principal components analysis for longitudinal.pdf:G\:\\My Drive\\paper\\Jiang_Wang_2010_Covariate adjusted functional principal components analysis for longitudinal.pdf:application/pdf},
}

@article{febrero-bande_functional_2017,
	title = {Functional {Principal} {Component} {Regression} and {Functional} {Partial} {Least}-squares {Regression}: {An} {Overview} and a {Comparative} {Study}},
	volume = {85},
	copyright = {©2015 The Authors. International Statistical Review © 2015 International Statistical Institute},
	issn = {1751-5823},
	shorttitle = {Functional {Principal} {Component} {Regression} and {Functional} {Partial} {Least}-squares {Regression}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12116},
	doi = {10.1111/insr.12116},
	abstract = {Functional data analysis is a field of growing importance in Statistics. In particular, the functional linear model with scalar response is surely the model that has attracted more attention in both theoretical and applied research. Two of the most important methodologies used to estimate the parameters of the functional linear model with scalar response are functional principal component regression and functional partial least-squares regression. We provide an overview of estimation methods based on these methodologies and discuss their advantages and disadvantages. We emphasise that the role played by the functional principal components and by the functional partial least-squares components that are used in estimation appears to be very important to estimate the functional slope of the model. A functional version of the best subset selection strategy usual in multiple linear regression is also analysed. Finally, we present an extensive comparative simulation study to compare the performance of all the considered methodologies that may help practitioners in the use of the functional linear model with scalar response.},
	language = {en},
	number = {1},
	urldate = {2023-09-30},
	journal = {International Statistical Review},
	author = {Febrero-Bande, Manuel and Galeano, Pedro and González-Manteiga, Wenceslao},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12116},
	keywords = {Cross-validation, eigenfunctions, eigenvalues, functional linear model, functional partial least squares, functional principal components},
	pages = {61--83},
	file = {Int Statistical Rev - 2015 - Febrero%E2%80%90Bande.pdf:C\:\\Users\\Jongmin\\Zotero\\storage\\U8MNQ2LD\\Int Statistical Rev - 2015 - Febrero%E2%80%90Bande.pdf:application/pdf},
}

@article{reiss_functional_2007,
	title = {Functional {Principal} {Component} {Regression} and {Functional} {Partial} {Least} {Squares}},
	volume = {102},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214507000000527},
	doi = {10.1198/016214507000000527},
	abstract = {Regression of a scalar response on signal predictors, such as near-infrared (NIR) spectra of chemical samples, presents a major challenge when, as is typically the case, the dimension of the signals far exceeds their number. Most solutions to this problem reduce the dimension of the predictors either by regressing on components [e.g., principal component regression (PCR) and partial least squares (PLS)] or by smoothing methods, which restrict the coefficient function to the span of a spline basis. This article introduces functional versions of PCR and PLS, which combine both of the foregoing dimension-reduction approaches. Two versions of functional PCR are developed, both using B-splines and roughness penalties. The regularized-components version applies such a penalty to the construction of the principal components (i.e., it uses functional principal components), whereas the regularized-regression version incorporates a penalty in the regression. For the latter form of functional PCR, the penalty parameter may be selected by generalized cross-validation, restricted maximum likelihood (REML), or a minimum mean integrated squared error criterion. Proceeding similarly, we develop two versions of functional PLS. Asymptotic convergence properties of regularized-regression functional PCR are demonstrated. A simulation study and split-sample validation with several NIR spectroscopy data sets indicate that functional PCR and functional PLS, especially the regularized-regression versions with REML, offer advantages over existing methods in terms of both estimation of the coefficient function and prediction of future observations.},
	number = {479},
	urldate = {2023-10-01},
	journal = {Journal of the American Statistical Association},
	author = {Reiss, Philip T and Ogden, R. Todd},
	month = sep,
	year = {2007},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1198/016214507000000527},
	keywords = {B-splines, Functional linear model, Linear mixed model, Multivariate calibration, Signal regression, SIMPLS},
	pages = {984--996},
	file = {Reiss_Ogden_2007_Functional Principal Component Regression and Functional Partial Least Squares.pdf:G\:\\My Drive\\paper\\Reiss_Ogden_2007_Functional Principal Component Regression and Functional Partial Least Squares.pdf:application/pdf},
}

@article{happ_multivariate_2018,
	title = {Multivariate {Functional} {Principal} {Component} {Analysis} for {Data} {Observed} on {Different} ({Dimensional}) {Domains}},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2016.1273115},
	doi = {10.1080/01621459.2016.1273115},
	abstract = {Existing approaches for multivariate functional principal component analysis are restricted to data on the same one-dimensional interval. The presented approach focuses on multivariate functional data on different domains that may differ in dimension, such as functions and images. The theoretical basis for multivariate functional principal component analysis is given in terms of a Karhunen–Loève Theorem. For the practically relevant case of a finite Karhunen–Loève representation, a relationship between univariate and multivariate functional principal component analysis is established. This offers an estimation strategy to calculate multivariate functional principal components and scores based on their univariate counterparts. For the resulting estimators, asymptotic results are derived. The approach can be extended to finite univariate expansions in general, not necessarily orthonormal bases. It is also applicable for sparse functional data or data with measurement error. A flexible R implementation is available on CRAN. The new method is shown to be competitive to existing approaches for data observed on a common one-dimensional domain. The motivating application is a neuroimaging study, where the goal is to explore how longitudinal trajectories of a neuropsychological test score covary with FDG-PET brain scans at baseline. Supplementary material, including detailed proofs, additional simulation results, and software is available online.},
	number = {522},
	urldate = {2023-10-01},
	journal = {Journal of the American Statistical Association},
	author = {Happ, Clara and Greven, Sonja},
	month = apr,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2016.1273115},
	keywords = {Dimension reduction, Functional data analysis, Image analysis, Multivariate functional data},
	pages = {649--659},
	file = {Happ_Greven_2018_Multivariate Functional Principal Component Analysis for Data Observed on.pdf:G\:\\My Drive\\paper\\Happ_Greven_2018_Multivariate Functional Principal Component Analysis for Data Observed on2.pdf:application/pdf},
}
